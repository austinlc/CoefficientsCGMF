{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CGMF Summary File Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import math\n",
    "import os\n",
    "from statistics import *\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fileInt(name):\n",
    "    if (name.find(\"YIELDS\") != -1):\n",
    "        return int(name[name.find(\"YIELDS\")+6:])\n",
    "    else:\n",
    "        return 1000000\n",
    "\n",
    "def makeSummaryFile(filepath, summaryFileName, ParamName, ParamArr, option = 'meanvals'):\n",
    "    \n",
    "    # the intent of the variable \"option\" is to allow for other types of summary files to be generated\n",
    "    # for example a P(nu) summary file\n",
    "    \n",
    "    \n",
    "    # check the filepath : the path for the outputfiles as well as the summary file\n",
    "    if not os.path.isdir(filepath):\n",
    "        raise ValueError('You do not have the directory {} in your current working directory'.format(filepath))\n",
    "\n",
    "    print(sorted(os.listdir(filepath), key=lambda x: fileInt(x)))\n",
    "    \n",
    "    \n",
    "    # ** OVERWRITE ** if there exists the file summaryFileName\n",
    "    summary_file_path = os.path.join(filepath, summaryFileName)\n",
    "    if os.path.isfile(summary_file_path):\n",
    "        f = open(summary_file_path, 'w')\n",
    "        f.close()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # write the header according to the option\n",
    "    if (option == 'meanvals'):\n",
    "        f = open(summary_file_path, 'w')\n",
    "        f.write(\"#CGMF SUMMARY FILE\\n\")\n",
    "        f.write(\"#Generated: \" + str(datetime.now().strftime(\"%Y-%m-%d %H:%M\")) + \"\\n\")\n",
    "        f.write(\"#Number of CGMF Output Files: {0:2d}\\n#\\n\".format(len(os.listdir(filepath))))\n",
    "        f.write(\"#File\\t\\t\\t\\t\\t\\t\\t\\t\\t# Hist\\t{}\\t\\t<TXE>\\t1sig\\t\\t<TKE>\\t1sig\\t\\t<J>\\t\\t1sig\\t\\t<nn>\\tn-mom2\\tn-mom3\\t<ng>\\tg-mom2\\tg-mom3\\t<En>CM\\t1sig\\t\\t<Eg>CM\\t1sig\\t\\t<En>Lab\\t1sig\\t\\t<Eg>Lab\\t1sig\\n\".format(ParamName))\n",
    "        f.write(\"#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\")\n",
    "        f.close()\n",
    "        \n",
    "    # gather the data file by file and write to file according to option\n",
    "    \n",
    "    # if user desires, a specific number of histories can be read, otherwise the max is infinite\n",
    "    MaxHistories = 100000\n",
    "\n",
    "    # total number of files to be read\n",
    "    n_files = len(os.listdir(filepath))\n",
    "\n",
    "    # initialize the index of the files to 0\n",
    "    file_index = 0\n",
    "\n",
    "    # From filepath, read the files individually\n",
    "    # reads all files in order according to listdir\n",
    "\n",
    "    for filename in sorted(os.listdir(filepath), key=lambda x: fileInt(x)):\n",
    "        \n",
    "        #skip the iteration of the summaryfile\n",
    "        if (filename == summaryFileName):\n",
    "            continue\n",
    "\n",
    "        file_index += 1\n",
    "        file_loc = os.path.join(filepath,filename)\n",
    "        working_file = open(file_loc)\n",
    "\n",
    "        # read first line -----------------------------------------------------------------------------------------------\n",
    "        line = working_file.readline()\n",
    "        if (line.find(\"#\")!=0):\n",
    "            sys.exit(\"ERROR: FIRST LINE OF OUTPUT FILE SHOULD CONTAIN '#'\")\n",
    "        else:    \n",
    "            data          = line[1:].split()\n",
    "            ZAIDc         = int(data[0])\n",
    "            Zc            = int(ZAIDc/1000)\n",
    "            Ac            = int(ZAIDc)-1000*Zc\n",
    "            Asym          = int(float(Ac)/2.0)\n",
    "            Einc          = float(data[1])\n",
    "            nevents       = int(data[2])\n",
    "            alpha         = float(data[3])\n",
    "\n",
    "        # read remainder -----------------------------------------------------------------------------------------------\n",
    "        nfragments = 0\n",
    "\n",
    "        # re-initialize all arrays\n",
    "        # Line 1 Arrays of interest\n",
    "\n",
    "        Ul, Uh, TXE      = [], [], []\n",
    "        Jl, Jh, J        = [], [], []\n",
    "        KEl, KEh, TKE    = [], [], []\n",
    "        nnl, nnh, nnt    = [], [], []\n",
    "        ngl, ngh, ngt    = [], [], []\n",
    "\n",
    "        # Direction/momentum vectors are arranged with CoM first, then Lab\n",
    "        # Fragment momentum arrays - Line 2\n",
    "        #Pcml, Pcmh       = [], []\n",
    "        #Plabl, Plabh     = [], []\n",
    "\n",
    "        # For now, just save the resulting particle energies\n",
    "        # Neutron Energies - Line 3\n",
    "        Encml, Encmh     = [], []\n",
    "        Enlabl, Enlabh   = [], []\n",
    "\n",
    "        # Gamma Energies - Line 4\n",
    "        Egcml, Egcmh     = [], []\n",
    "        Eglabl, Eglabh   = [], []\n",
    "\n",
    "        while True:\n",
    "            line = working_file.readline()\n",
    "            if (len(line)==0):\n",
    "                break\n",
    "            #LINE ONE OF FISSION EVENT (A, Z, U, J, P, KE, nn, ng, nIC)\n",
    "            nfragments+=1\n",
    "            tempdata1 = line.split()\n",
    "            if (nfragments % 2 == 1): # LIGHT FRAGMENT\n",
    "                Ul.append(float(tempdata1[2]))\n",
    "                Jl.append(float(tempdata1[3]))\n",
    "                KEl.append(float(tempdata1[5]))\n",
    "                nnl.append(int(tempdata1[6]))\n",
    "                ngl.append(int(tempdata1[7]))\n",
    "\n",
    "            else: # HEAVY FRAGMENT\n",
    "                Uh.append(float(tempdata1[2]))\n",
    "                Jh.append(float(tempdata1[3]))\n",
    "                KEh.append(float(tempdata1[5]))\n",
    "                nnh.append(int(tempdata1[6]))\n",
    "                ngh.append(int(tempdata1[7]))\n",
    "\n",
    "\n",
    "            #LINE TWO OF FISSION EVENT (momentum vector in Lab and center of mass of FRAGMENT)\n",
    "            line = working_file.readline()\n",
    "            tempdata2 = line.split()\n",
    "            # for now, don't worry about line 2\n",
    "\n",
    "            #LINE THREE OF FISSION EVENT (Neutron direction cosines and energies, Lab and center of mass respectively)\n",
    "            if (int(tempdata1[6]) != 0):\n",
    "                line = working_file.readline()\n",
    "                tempdata3 = line.split()\n",
    "                if (nfragments % 2 == 1): # LIGHT FRAGMENT\n",
    "                    for i in range(int(tempdata1[6])):\n",
    "                        Encml.append(float(tempdata3[4*i + 7]))\n",
    "                        Enlabl.append(float(tempdata3[8*i + 7]))\n",
    "                else: # HEAVY FRAGMENT\n",
    "                    for i in range(int(tempdata1[6])):\n",
    "                        Encmh.append(float(tempdata3[4*i + 7]))\n",
    "                        Enlabh.append(float(tempdata3[8*i + 7]))\n",
    "\n",
    "\n",
    "            #LINE FOUR OF FISSION EVENT (Gamma direction cosines and energies, Lab and center of mass respectively)\n",
    "            if (int(tempdata1[7]) != 0):\n",
    "                line = working_file.readline()\n",
    "                tempdata4 = line.split()\n",
    "                if (nfragments % 2 == 1): # LIGHT FRAGMENT\n",
    "                    for i in range(int(tempdata1[7])):\n",
    "                        Egcml.append(float(tempdata4[4*i + 7]))\n",
    "                        Eglabl.append(float(tempdata4[8*i + 7]))\n",
    "                else: # HEAVY FRAGMENT\n",
    "                    for i in range(int(tempdata1[7])):\n",
    "                        Egcmh.append(float(tempdata4[4*i + 7]))\n",
    "                        Eglabh.append(float(tempdata4[8*i + 7]))\n",
    "\n",
    "            if (nfragments>=MaxHistories*2):\n",
    "                break\n",
    "        nhistories = nfragments/2\n",
    "\n",
    "        # Concatenate arrays\n",
    "        TXE    = np.sum([Ul , Uh], axis=0)\n",
    "        J      = Jl + Jh\n",
    "        TKE    = np.sum([KEl , KEh], axis=0)\n",
    "        nnt    = np.sum([nnl , nnh], axis=0)\n",
    "        nn2t   = [float(nnt[i] * (nnt[i]-1)) for i in range(len(nnt))] # 2nd factorial moment\n",
    "        nn3t   = [float(nnt[i] * (nnt[i]-1) * (nnt[i]-2)) for i in range(len(nnt))] # 3rd factorial moment\n",
    "        ngt    = np.sum([ngl , ngh], axis=0)\n",
    "        ng2t   = [float(ngt[i] * (ngt[i]-1)) for i in range(len(ngt))]\n",
    "        ng3t   = [float(ngt[i] * (ngt[i]-1) * (ngt[i]-2)) for i in range(len(ngt))]\n",
    "        Encm  = Encml + Encmh\n",
    "        Egcm  = Egcml + Egcmh\n",
    "        Enlab = Enlabl + Enlabh\n",
    "        Eglab = Eglabl + Eglabh\n",
    "\n",
    "        # Close File that is read\n",
    "        working_file.close()\n",
    "\n",
    "        # Open Summary File\n",
    "\n",
    "        summary = open(summary_file_path,\"a\")\n",
    "        \n",
    "        # tabsstr aligns the second column\n",
    "        tabsstr = ''\n",
    "        for i in range(int(math.ceil((44.0-float(len(filename)))/8.0))):\n",
    "            tabsstr = tabsstr + \"\\t\"\n",
    "\n",
    "\n",
    "        if(option == 'meanvals'):\n",
    "            concstr = filename + tabsstr + '{:d}\\t{:0.3f}\\t{:0.3f}\\t{:0.3E}\\t{:0.3f}\\t{:0.3E}\\t{:0.3f}\\t{:0.3E}\\t\\\n",
    "        {:0.3f}\\t{:0.3f}\\t{:0.3f}\\t{:0.3f}\\t{:0.3f}\\t{:0.2f}\\t{:0.3f}\\t{:0.3E}\\t{:0.3f}\\t{:0.3E}\\t{:0.3f}\\t{:0.3E}\\t{:0.3f}\\t{:0.3E}\\n'.format(\n",
    "                            int(nhistories), ParamArr[file_index -1],\n",
    "                            mean(TXE), pstdev(TXE),  \n",
    "                            mean(TKE), pstdev(TKE), mean(J),\n",
    "                            pstdev(J), mean(nnt.astype(float)), mean(nn2t),\n",
    "                            mean(nn3t), mean(ngt.astype(float)), mean(ng2t), mean(ng3t), mean(Encm), pstdev(Encm), \n",
    "                            mean(Egcm), pstdev(Egcm), mean(Enlab), pstdev(Enlab), mean(Eglab), pstdev(Eglab))\n",
    "\n",
    "            summary.write(concstr)\n",
    "            \n",
    "        summary.close()\n",
    "        print( \"{:0.1f}% complete\".format(file_index/(n_files-1)*100))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up the parameters dictionary\n",
    "\n",
    "w = [0.8128359323532158, 0.1734091083059585, 0.013754959340825731]\n",
    "dmin= [14.4946848, 10.8924571, 16.7133975]\n",
    "dmax =[18.2042691, 17.322745, 20.4274353]\n",
    "ddec =[0.446051597, 0.134703577, 0.165676002]\n",
    "Abar =[144.542941, 136.328441, 127.53033]\n",
    "sigA =[6.11049848, 3.69590546, 18.225735]\n",
    "\n",
    "PARAMSdict   = {}\n",
    "PARAMSdict['w0'] = np.linspace(0.75, 0.9862, 10)\n",
    "PARAMSdict['w0'] = np.insert(PARAMSdict['w0'], 0, w[0])\n",
    "\n",
    "PARAMSdict['w1'] = np.linspace(0.15, 0.25, 10)\n",
    "PARAMSdict['w1'] = np.insert(PARAMSdict['w1'], 0, w[1])\n",
    "\n",
    "PARAMSdict['w2'] = np.linspace(0.001, 0.07, 10)\n",
    "PARAMSdict['w2'] = np.delete(PARAMSdict['w2'] , 2)\n",
    "PARAMSdict['w2'] = np.insert(PARAMSdict['w2'], 0, w[2])\n",
    "\n",
    "PARAMSdict['dmin0'] = np.linspace(10.,18.,10)\n",
    "PARAMSdict['dmin0'] = np.delete(PARAMSdict['dmin0'] , 2)\n",
    "PARAMSdict['dmin0'] = np.insert(PARAMSdict['dmin0'], 0, dmin[0])\n",
    "\n",
    "PARAMSdict['dmin1'] = np.linspace(6.,16.,10)\n",
    "PARAMSdict['dmin1'] = np.delete(PARAMSdict['dmin1'] , 3)\n",
    "PARAMSdict['dmin1'] = np.delete(PARAMSdict['dmin1'] , 8) #for some reason file 50 is giving us issues.. just delete\n",
    "PARAMSdict['dmin1'] = np.insert(PARAMSdict['dmin1'], 0, dmin[1])\n",
    "\n",
    "PARAMSdict['dmin2'] = np.linspace(10.,20.,10)\n",
    "PARAMSdict['dmin2'] = np.insert(PARAMSdict['dmin2'], 0, dmin[2])\n",
    "\n",
    "PARAMSdict['dmax0'] = np.linspace(18.286,18.716,10)\n",
    "# PARAMSdict['dmax0'] = np.delete(PARAMSdict['dmax0'] , 7)\n",
    "PARAMSdict['dmax0'] = np.insert(PARAMSdict['dmax0'], 0, dmax[0])\n",
    "\n",
    "PARAMSdict['dmax1'] = np.linspace(15.5426,17.432,10)\n",
    "PARAMSdict['dmax1'] = np.delete(PARAMSdict['dmax1'], 3)\n",
    "PARAMSdict['dmax1'] = np.insert(PARAMSdict['dmax1'], 0, dmax[1])\n",
    "\n",
    "PARAMSdict['dmax2'] = np.linspace(17.,26.,10)\n",
    "PARAMSdict['dmax2'] = np.insert(PARAMSdict['dmax2'], 0, dmax[2])\n",
    "\n",
    "PARAMSdict['ddec0'] = np.linspace(0.2,0.8,10)\n",
    "# PARAMSdict['ddec0'] = np.delete(PARAMSdict['ddec0'], 6)\n",
    "PARAMSdict['ddec0'] = np.insert(PARAMSdict['ddec0'], 0, ddec[0])\n",
    "\n",
    "PARAMSdict['ddec1'] = np.linspace(0.05,0.3,10)\n",
    "PARAMSdict['ddec1'] = np.delete(PARAMSdict['ddec1'], 0)\n",
    "PARAMSdict['ddec1'] = np.insert(PARAMSdict['ddec1'], 0, ddec[1])\n",
    "\n",
    "PARAMSdict['ddec2'] = np.linspace(0.05,0.4,10)\n",
    "PARAMSdict['ddec2'] = np.insert(PARAMSdict['ddec2'], 0, ddec[2])\n",
    "\n",
    "PARAMSdict['Abar0'] = np.linspace(144.1,149.,10)\n",
    "PARAMSdict['Abar0'] = np.insert(PARAMSdict['Abar0'], 0, Abar[0])\n",
    "\n",
    "PARAMSdict['Abar1'] = np.linspace(128.,140.,10)\n",
    "PARAMSdict['Abar1'] = np.delete(PARAMSdict['Abar1'], 7)\n",
    "PARAMSdict['Abar1'] = np.delete(PARAMSdict['Abar1'], 8)\n",
    "PARAMSdict['Abar1'] = np.insert(PARAMSdict['Abar1'], 0, Abar[1])\n",
    "\n",
    "PARAMSdict['sigA0'] = np.linspace(4.0,8.0,10)\n",
    "PARAMSdict['sigA0'] = np.insert(PARAMSdict['sigA0'], 0, sigA[0])\n",
    "\n",
    "PARAMSdict['sigA1'] = np.linspace(2.5,5.5,10)\n",
    "PARAMSdict['sigA1'] = np.delete(PARAMSdict['sigA1'], 2)\n",
    "PARAMSdict['sigA1'] = np.insert(PARAMSdict['sigA1'], 0, sigA[1])\n",
    "\n",
    "PARAMSdict['sigA2'] = np.linspace(12.0,30.0,10)\n",
    "for i in range(5,10):\n",
    "    PARAMSdict['sigA2'] = np.delete(PARAMSdict['sigA2'],5)\n",
    "PARAMSdict['sigA2'] = np.insert(PARAMSdict['sigA2'], 0, sigA[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['histories-vectors.CGMF.252CfYIELDS0', 'histories-vectors.CGMF.252CfYIELDS1', 'histories-vectors.CGMF.252CfYIELDS2', 'histories-vectors.CGMF.252CfYIELDS3', 'histories-vectors.CGMF.252CfYIELDS4', 'histories-vectors.CGMF.252CfYIELDS5', 'histories-vectors.CGMF.252CfYIELDS6', 'histories-vectors.CGMF.252CfYIELDS7', 'histories-vectors.CGMF.252CfYIELDS8', 'histories-vectors.CGMF.252CfYIELDS9', 'histories-vectors.CGMF.252CfYIELDS10', 'summary_w0.txt']\n",
      "9.1% complete\n",
      "18.2% complete\n",
      "27.3% complete\n",
      "36.4% complete\n",
      "45.5% complete\n",
      "54.5% complete\n",
      "63.6% complete\n",
      "72.7% complete\n",
      "81.8% complete\n",
      "90.9% complete\n",
      "100.0% complete\n",
      "['histories-vectors.CGMF.252CfYIELDS0', 'histories-vectors.CGMF.252CfYIELDS11', 'histories-vectors.CGMF.252CfYIELDS12', 'histories-vectors.CGMF.252CfYIELDS13', 'histories-vectors.CGMF.252CfYIELDS14', 'histories-vectors.CGMF.252CfYIELDS15', 'histories-vectors.CGMF.252CfYIELDS16', 'histories-vectors.CGMF.252CfYIELDS17', 'histories-vectors.CGMF.252CfYIELDS18', 'histories-vectors.CGMF.252CfYIELDS19', 'histories-vectors.CGMF.252CfYIELDS20', 'summary_w1.txt']\n",
      "9.1% complete\n",
      "18.2% complete\n",
      "27.3% complete\n",
      "36.4% complete\n",
      "45.5% complete\n",
      "54.5% complete\n",
      "63.6% complete\n",
      "72.7% complete\n",
      "81.8% complete\n",
      "90.9% complete\n",
      "100.0% complete\n",
      "['histories-vectors.CGMF.252CfYIELDS0', 'histories-vectors.CGMF.252CfYIELDS21', 'histories-vectors.CGMF.252CfYIELDS22', 'histories-vectors.CGMF.252CfYIELDS24', 'histories-vectors.CGMF.252CfYIELDS25', 'histories-vectors.CGMF.252CfYIELDS26', 'histories-vectors.CGMF.252CfYIELDS27', 'histories-vectors.CGMF.252CfYIELDS28', 'histories-vectors.CGMF.252CfYIELDS29', 'histories-vectors.CGMF.252CfYIELDS30', 'summary_w2.txt']\n",
      "10.0% complete\n",
      "20.0% complete\n",
      "30.0% complete\n",
      "40.0% complete\n",
      "50.0% complete\n",
      "60.0% complete\n",
      "70.0% complete\n",
      "80.0% complete\n",
      "90.0% complete\n",
      "100.0% complete\n",
      "['histories-vectors.CGMF.252CfYIELDS0', 'histories-vectors.CGMF.252CfYIELDS31', 'histories-vectors.CGMF.252CfYIELDS32', 'histories-vectors.CGMF.252CfYIELDS34', 'histories-vectors.CGMF.252CfYIELDS35', 'histories-vectors.CGMF.252CfYIELDS36', 'histories-vectors.CGMF.252CfYIELDS37', 'histories-vectors.CGMF.252CfYIELDS38', 'histories-vectors.CGMF.252CfYIELDS39', 'histories-vectors.CGMF.252CfYIELDS40', 'summary_dmin0.txt']\n",
      "10.0% complete\n",
      "20.0% complete\n",
      "30.0% complete\n",
      "40.0% complete\n",
      "50.0% complete\n",
      "60.0% complete\n",
      "70.0% complete\n",
      "80.0% complete\n",
      "90.0% complete\n",
      "100.0% complete\n",
      "['histories-vectors.CGMF.252CfYIELDS0', 'histories-vectors.CGMF.252CfYIELDS41', 'histories-vectors.CGMF.252CfYIELDS42', 'histories-vectors.CGMF.252CfYIELDS43', 'histories-vectors.CGMF.252CfYIELDS45', 'histories-vectors.CGMF.252CfYIELDS46', 'histories-vectors.CGMF.252CfYIELDS47', 'histories-vectors.CGMF.252CfYIELDS48', 'histories-vectors.CGMF.252CfYIELDS49', 'summary_dmin1.txt']\n",
      "11.1% complete\n",
      "22.2% complete\n",
      "33.3% complete\n",
      "44.4% complete\n",
      "55.6% complete\n",
      "66.7% complete\n",
      "77.8% complete\n",
      "88.9% complete\n",
      "100.0% complete\n",
      "['histories-vectors.CGMF.252CfYIELDS0', 'histories-vectors.CGMF.252CfYIELDS51', 'histories-vectors.CGMF.252CfYIELDS52', 'histories-vectors.CGMF.252CfYIELDS53', 'histories-vectors.CGMF.252CfYIELDS54', 'histories-vectors.CGMF.252CfYIELDS55', 'histories-vectors.CGMF.252CfYIELDS56', 'histories-vectors.CGMF.252CfYIELDS57', 'histories-vectors.CGMF.252CfYIELDS58', 'histories-vectors.CGMF.252CfYIELDS59', 'histories-vectors.CGMF.252CfYIELDS60', 'summary_dmin2.txt']\n",
      "9.1% complete\n",
      "18.2% complete\n",
      "27.3% complete\n",
      "36.4% complete\n",
      "45.5% complete\n",
      "54.5% complete\n",
      "63.6% complete\n",
      "72.7% complete\n",
      "81.8% complete\n",
      "90.9% complete\n",
      "100.0% complete\n",
      "['histories-vectors.CGMF.252CfYIELDS0', 'histories-vectors.CGMF.252CfYIELDS61', 'histories-vectors.CGMF.252CfYIELDS62', 'histories-vectors.CGMF.252CfYIELDS63', 'histories-vectors.CGMF.252CfYIELDS64', 'histories-vectors.CGMF.252CfYIELDS65', 'histories-vectors.CGMF.252CfYIELDS66', 'histories-vectors.CGMF.252CfYIELDS67', 'histories-vectors.CGMF.252CfYIELDS68', 'histories-vectors.CGMF.252CfYIELDS69', 'histories-vectors.CGMF.252CfYIELDS70', 'summary_dmax0.txt']\n",
      "9.1% complete\n",
      "18.2% complete\n",
      "27.3% complete\n",
      "36.4% complete\n",
      "45.5% complete\n",
      "54.5% complete\n",
      "63.6% complete\n",
      "72.7% complete\n",
      "81.8% complete\n",
      "90.9% complete\n",
      "100.0% complete\n",
      "['histories-vectors.CGMF.252CfYIELDS0', 'histories-vectors.CGMF.252CfYIELDS71', 'histories-vectors.CGMF.252CfYIELDS72', 'histories-vectors.CGMF.252CfYIELDS73', 'histories-vectors.CGMF.252CfYIELDS75', 'histories-vectors.CGMF.252CfYIELDS76', 'histories-vectors.CGMF.252CfYIELDS77', 'histories-vectors.CGMF.252CfYIELDS78', 'histories-vectors.CGMF.252CfYIELDS79', 'histories-vectors.CGMF.252CfYIELDS80', 'summary_dmax1.txt']\n",
      "10.0% complete\n",
      "20.0% complete\n",
      "30.0% complete\n",
      "40.0% complete\n",
      "50.0% complete\n",
      "60.0% complete\n",
      "70.0% complete\n",
      "80.0% complete\n",
      "90.0% complete\n",
      "100.0% complete\n",
      "['histories-vectors.CGMF.252CfYIELDS0', 'histories-vectors.CGMF.252CfYIELDS81', 'histories-vectors.CGMF.252CfYIELDS82', 'histories-vectors.CGMF.252CfYIELDS83', 'histories-vectors.CGMF.252CfYIELDS84', 'histories-vectors.CGMF.252CfYIELDS85', 'histories-vectors.CGMF.252CfYIELDS86', 'histories-vectors.CGMF.252CfYIELDS87', 'histories-vectors.CGMF.252CfYIELDS88', 'histories-vectors.CGMF.252CfYIELDS89', 'histories-vectors.CGMF.252CfYIELDS90', 'summary_dmax2.txt']\n",
      "9.1% complete\n",
      "18.2% complete\n",
      "27.3% complete\n",
      "36.4% complete\n",
      "45.5% complete\n",
      "54.5% complete\n",
      "63.6% complete\n",
      "72.7% complete\n",
      "81.8% complete\n",
      "90.9% complete\n",
      "100.0% complete\n",
      "['histories-vectors.CGMF.252CfYIELDS0', 'histories-vectors.CGMF.252CfYIELDS91', 'histories-vectors.CGMF.252CfYIELDS92', 'histories-vectors.CGMF.252CfYIELDS93', 'histories-vectors.CGMF.252CfYIELDS94', 'histories-vectors.CGMF.252CfYIELDS95', 'histories-vectors.CGMF.252CfYIELDS96', 'histories-vectors.CGMF.252CfYIELDS97', 'histories-vectors.CGMF.252CfYIELDS98', 'histories-vectors.CGMF.252CfYIELDS99', 'histories-vectors.CGMF.252CfYIELDS100', 'summary_ddec0.txt']\n",
      "9.1% complete\n",
      "18.2% complete\n",
      "27.3% complete\n",
      "36.4% complete\n",
      "45.5% complete\n",
      "54.5% complete\n",
      "63.6% complete\n",
      "72.7% complete\n",
      "81.8% complete\n",
      "90.9% complete\n",
      "100.0% complete\n",
      "['histories-vectors.CGMF.252CfYIELDS0', 'histories-vectors.CGMF.252CfYIELDS102', 'histories-vectors.CGMF.252CfYIELDS103', 'histories-vectors.CGMF.252CfYIELDS104', 'histories-vectors.CGMF.252CfYIELDS105', 'histories-vectors.CGMF.252CfYIELDS106', 'histories-vectors.CGMF.252CfYIELDS107', 'histories-vectors.CGMF.252CfYIELDS108', 'histories-vectors.CGMF.252CfYIELDS109', 'histories-vectors.CGMF.252CfYIELDS110', 'summary_ddec1.txt']\n",
      "10.0% complete\n",
      "20.0% complete\n",
      "30.0% complete\n",
      "40.0% complete\n",
      "50.0% complete\n",
      "60.0% complete\n",
      "70.0% complete\n",
      "80.0% complete\n",
      "90.0% complete\n",
      "100.0% complete\n",
      "['histories-vectors.CGMF.252CfYIELDS0', 'histories-vectors.CGMF.252CfYIELDS111', 'histories-vectors.CGMF.252CfYIELDS112', 'histories-vectors.CGMF.252CfYIELDS113', 'histories-vectors.CGMF.252CfYIELDS114', 'histories-vectors.CGMF.252CfYIELDS115', 'histories-vectors.CGMF.252CfYIELDS116', 'histories-vectors.CGMF.252CfYIELDS117', 'histories-vectors.CGMF.252CfYIELDS118', 'histories-vectors.CGMF.252CfYIELDS119', 'histories-vectors.CGMF.252CfYIELDS120', 'summary_ddec2.txt']\n",
      "9.1% complete\n",
      "18.2% complete\n",
      "27.3% complete\n",
      "36.4% complete\n",
      "45.5% complete\n",
      "54.5% complete\n",
      "63.6% complete\n",
      "72.7% complete\n",
      "81.8% complete\n",
      "90.9% complete\n",
      "100.0% complete\n",
      "['histories-vectors.CGMF.252CfYIELDS0', 'histories-vectors.CGMF.252CfYIELDS121', 'histories-vectors.CGMF.252CfYIELDS122', 'histories-vectors.CGMF.252CfYIELDS123', 'histories-vectors.CGMF.252CfYIELDS124', 'histories-vectors.CGMF.252CfYIELDS125', 'histories-vectors.CGMF.252CfYIELDS126', 'histories-vectors.CGMF.252CfYIELDS127', 'histories-vectors.CGMF.252CfYIELDS128', 'histories-vectors.CGMF.252CfYIELDS129', 'histories-vectors.CGMF.252CfYIELDS130', 'summary_Abar0.txt']\n",
      "9.1% complete\n",
      "18.2% complete\n",
      "27.3% complete\n",
      "36.4% complete\n",
      "45.5% complete\n",
      "54.5% complete\n",
      "63.6% complete\n",
      "72.7% complete\n",
      "81.8% complete\n",
      "90.9% complete\n",
      "100.0% complete\n",
      "['histories-vectors.CGMF.252CfYIELDS0', 'histories-vectors.CGMF.252CfYIELDS131', 'histories-vectors.CGMF.252CfYIELDS132', 'histories-vectors.CGMF.252CfYIELDS133', 'histories-vectors.CGMF.252CfYIELDS134', 'histories-vectors.CGMF.252CfYIELDS135', 'histories-vectors.CGMF.252CfYIELDS136', 'histories-vectors.CGMF.252CfYIELDS137', 'histories-vectors.CGMF.252CfYIELDS139', 'summary_Abar1.txt']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.1% complete\n",
      "22.2% complete\n",
      "33.3% complete\n",
      "44.4% complete\n",
      "55.6% complete\n",
      "66.7% complete\n",
      "77.8% complete\n",
      "88.9% complete\n",
      "100.0% complete\n",
      "['histories-vectors.CGMF.252CfYIELDS0', 'histories-vectors.CGMF.252CfYIELDS141', 'histories-vectors.CGMF.252CfYIELDS142', 'histories-vectors.CGMF.252CfYIELDS143', 'histories-vectors.CGMF.252CfYIELDS144', 'histories-vectors.CGMF.252CfYIELDS145', 'histories-vectors.CGMF.252CfYIELDS146', 'histories-vectors.CGMF.252CfYIELDS147', 'histories-vectors.CGMF.252CfYIELDS148', 'histories-vectors.CGMF.252CfYIELDS149', 'histories-vectors.CGMF.252CfYIELDS150', 'summary_sigA0.txt']\n",
      "9.1% complete\n",
      "18.2% complete\n",
      "27.3% complete\n",
      "36.4% complete\n",
      "45.5% complete\n",
      "54.5% complete\n",
      "63.6% complete\n",
      "72.7% complete\n",
      "81.8% complete\n",
      "90.9% complete\n",
      "100.0% complete\n",
      "['histories-vectors.CGMF.252CfYIELDS0', 'histories-vectors.CGMF.252CfYIELDS151', 'histories-vectors.CGMF.252CfYIELDS152', 'histories-vectors.CGMF.252CfYIELDS154', 'histories-vectors.CGMF.252CfYIELDS155', 'histories-vectors.CGMF.252CfYIELDS156', 'histories-vectors.CGMF.252CfYIELDS157', 'histories-vectors.CGMF.252CfYIELDS158', 'histories-vectors.CGMF.252CfYIELDS159', 'histories-vectors.CGMF.252CfYIELDS160']\n",
      "10.0% complete\n",
      "20.0% complete\n",
      "30.0% complete\n",
      "40.0% complete\n",
      "50.0% complete\n",
      "60.0% complete\n",
      "70.0% complete\n",
      "80.0% complete\n",
      "90.0% complete\n",
      "100.0% complete\n",
      "['histories-vectors.CGMF.252CfYIELDS0', 'histories-vectors.CGMF.252CfYIELDS161', 'histories-vectors.CGMF.252CfYIELDS162', 'histories-vectors.CGMF.252CfYIELDS163', 'histories-vectors.CGMF.252CfYIELDS164', 'histories-vectors.CGMF.252CfYIELDS165']\n",
      "16.7% complete\n",
      "33.3% complete\n",
      "50.0% complete\n",
      "66.7% complete\n",
      "83.3% complete\n",
      "100.0% complete\n"
     ]
    }
   ],
   "source": [
    "DATAPATHbase = '/home/austinlc/Documents/SensitivityData2'\n",
    "\n",
    "for k,v in PARAMSdict.items():\n",
    "    DATAPATH = os.path.join(DATAPATHbase,k)\n",
    "    makeSummaryFile(DATAPATH, 'summary_{}.txt'.format(k), k, v)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
